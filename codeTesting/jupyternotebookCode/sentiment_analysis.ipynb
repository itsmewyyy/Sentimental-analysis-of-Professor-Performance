{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9d84c7df-5611-4567-b933-520dbad1c1ab",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "<h1>Analyzing Pamantasan ng Lungsod ng Pasig Student Sentiments Towards Professor Performance: A Naive Bayes Approach</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b29c5853-249d-4fd1-8316-74c28d75a7f1",
   "metadata": {},
   "source": [
    "Importing necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19fa74f5-02ef-4b84-b043-78117e16aaed",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import gradio as gr\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, precision_score, recall_score, f1_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c09384c9-25f0-411a-995c-5a2887eb53ae",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "<h2>DATA LOADING AND DESCRIPTION</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03ecbdcd-f767-4657-bcbe-9f0402b67a83",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "The program starts by reading the data from the \"Feedback.xlsx\" file and provides an informative summary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf79de17-00be-456c-a0b6-44d4ac80705d",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "cmt = pd.read_excel(\"Feedback.xlsx\")\n",
    "\n",
    "cmt.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e2b420f-4cc2-4dcc-82fe-60b9df900ff5",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "Summarization of dataset prints out total numbers per label type (-1, 0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5e302a1-8f07-42be-b924-1e34206d9089",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Summarizes the dataset\n",
    "print(\"DATASET\")\n",
    "print(\"DIMENSION: \", cmt.shape)\n",
    "print()\n",
    "print(\"SUMMARY\")\n",
    "print(cmt.groupby(\"Label\").size()) \n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6641b8f-d9c3-4f6e-a5a9-b4d66a345f00",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "<h2>DATA PREPROCESSING</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b4b9c50-fe2c-4c14-8516-39d11a88ac28",
   "metadata": {},
   "source": [
    "The data must undergo text cleaning and standardization to remove irrelevant information that doesn't contribute to the sentiment detection of text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7540208e-fadc-47ee-b848-2e40b7234667",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean comments to remove special characters\n",
    "def clean_cmt(text):\n",
    "    text = re.sub(r\"[^a-zA-Z0-9\\s]\", \"\", text) \n",
    "    text = text.lower() \n",
    "    return text\n",
    "\n",
    "cmt[\"cleaned_comments\"] = cmt[\"Comments\"].apply(clean_cmt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6de3cb4c-ec97-45ca-91c5-20f2ee3564e7",
   "metadata": {},
   "source": [
    "Creating a Bag-of-Words representation and vectorizing the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cee28ec5-15c8-445a-b2f5-ee6043aa94ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer()\n",
    "features = vectorizer.fit_transform(cmt[\"cleaned_comments\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7245a5f-9612-40a8-8e42-b3b13f41c664",
   "metadata": {},
   "source": [
    "To get an unbiased estimate of the model’s performance, we need to evaluate it on the data we didn’t use for training. The dataset is splitted using a single-split method."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b00a0f0d-5070-4b04-a506-d06c4f533ab2",
   "metadata": {},
   "source": [
    "80% of the data will be used for training and 20% will be used for testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0adcfa0-4d2d-4fc8-aa37-7d5deeb82386",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, X_test, y_train, y_test = train_test_split(features, cmt[\"Label\"], test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84c9365f-f89c-45b1-94bd-0e76fb511461",
   "metadata": {},
   "source": [
    "<h2>MODEL TRAINING AND EVALUATION</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c103f768-19c0-4673-bb4a-7c76374b2197",
   "metadata": {},
   "source": [
    "The model is then trained and tested. To evaluate the model performance metrics such as accuracy, precision, recall, and F1 score will be measured."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d37a131-96d3-4f08-8d4b-2720b1e26054",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MultinomialNB()\n",
    "model.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f84ebb2c-4cb5-4dea-93c5-77c9a1c0831f",
   "metadata": {},
   "source": [
    "<h3>Accuracy</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fa9ebea-e878-4752-a321-fa73ede1184e",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "308cfed0-1e20-45ed-aa9f-80861c5437b6",
   "metadata": {},
   "source": [
    "<h3>Precision and Recall</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af7a7c5f-8e50-4531-ae4e-999731a2cafe",
   "metadata": {},
   "source": [
    "Precision and recall usees a confusion matrix to introduce them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "193e4d8e-db6f-40fa-892c-f511d00bcb3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05d11ba8-7b54-4dba-b8cb-021a1b1c86a2",
   "metadata": {},
   "source": [
    "<h4>Visualizing the confusion matrix</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bd65007-eec8-47c9-8d57-9a0d2e24132c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_labels = {\n",
    "    -1: \"Negative\",\n",
    "    0: \"Neutral\",\n",
    "    1: \"Positive\"\n",
    "}\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(\n",
    "    cm,\n",
    "    annot=True,\n",
    "    fmt=\"d\",\n",
    "    cmap=\"Blues\",\n",
    "    xticklabels=[class_labels[i] for i in class_labels.keys()],\n",
    "    yticklabels=[class_labels[i] for i in class_labels.keys()],\n",
    ")\n",
    "\n",
    "plt.xlabel(\"Predicted Sentiment\")\n",
    "plt.ylabel(\"Actual Sentiment\")\n",
    "plt.title(\"Confusion Matrix for Sentiment Analysis\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae185087-3f68-469e-85b6-d22d175af1c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "precision = precision_score(y_test, y_pred, average=\"weighted\")\n",
    "recall = recall_score(y_test, y_pred, average=\"weighted\")\n",
    "\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c001a802-5a79-4162-8632-97a8305b0d17",
   "metadata": {},
   "source": [
    "<h3>F1 score</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a054c0cb-f4d5-4ad1-a60f-756f37b60931",
   "metadata": {},
   "source": [
    "F1 score is the harmonic between precision and recall. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf85a7ac-77e5-4d40-9ea1-d0551d061297",
   "metadata": {},
   "outputs": [],
   "source": [
    "f1 = f1_score(y_test, y_pred, average=\"weighted\")\n",
    "print(f\"F1 Score: {f1:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35f02ab5-44ee-408d-a7d4-dd3e9cb253e5",
   "metadata": {},
   "source": [
    "<h2>PREDICTING SENTIMENT OF NEW FEEDBACK</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4678fbd-4216-4ad1-9b54-0f1ef51a7b3a",
   "metadata": {},
   "source": [
    "Using gradio to simulate the uploading process and sentimental analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1de15e2b-036b-4192-ae60-816213b480e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentiment(file):\n",
    "    cmt = pd.read_excel(file) \n",
    "    texts = cmt[\"Feedback\"]\n",
    "\n",
    "    sentiments = []\n",
    "    for text in texts:\n",
    "        cleaned_comment = clean_cmt(text) \n",
    "        new_features = vectorizer.transform([cleaned_comment])\n",
    "        predicted_sentiment = model.predict(new_features)[0]\n",
    "\n",
    "        if predicted_sentiment == 1:\n",
    "            sentiment = \"Positive\"\n",
    "        elif predicted_sentiment == 0:\n",
    "            sentiment = \"Neutral\"\n",
    "        elif predicted_sentiment == -1:\n",
    "            sentiment = \"Negative\"\n",
    "\n",
    "        sentiments.append(sentiment)\n",
    "\n",
    "    sentiment_output = \"\"\n",
    "    for i, row in cmt.iterrows(): #iterates each row \n",
    "        sentiment = sentiments[i]\n",
    "        text = row[\"Feedback\"]\n",
    "        sentiment_output += f\"{text}:  {sentiment}\\n\"  \n",
    "\n",
    "    return sentiment_output\n",
    "    \n",
    "#Creating a gradio interface\n",
    "app =  gr.Interface(title = \"Sentiment analysis\", description = \"Analyzing Pamantasan ng Lungsod ng Pasig Student Sentiments Towards Professor Performance: A Naive Bayes Approach\", fn = sentiment, inputs = [gr.File(label=\"Upload a file\")], outputs = \"textbox\")\n",
    "app.launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0bba043-5df5-417b-9765-2818222a2b9a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
