{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9d84c7df-5611-4567-b933-520dbad1c1ab",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "<h1>Analyzing Pamantasan ng Lungsod ng Pasig Student Sentiments Towards Professor Performance: A Naive Bayes Approach</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b29c5853-249d-4fd1-8316-74c28d75a7f1",
   "metadata": {},
   "source": [
    "Importing necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "19fa74f5-02ef-4b84-b043-78117e16aaed",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import gradio as gr\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, precision_score, recall_score, f1_score\n",
    "\n",
    "# Download NLTK Data\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c09384c9-25f0-411a-995c-5a2887eb53ae",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "<h2>DATA LOADING AND DESCRIPTION</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03ecbdcd-f767-4657-bcbe-9f0402b67a83",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "The program starts by reading the data from the \"Feedback.xlsx\" file and provides an informative summary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf79de17-00be-456c-a0b6-44d4ac80705d",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'venv (Python 3.12.4)' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'c:/Users/Wayan/Desktop/Sentimental-analysis-of-Professor-Performance/venv/Scripts/python.exe -m pip install ipykernel -U --force-reinstall'"
     ]
    }
   ],
   "source": [
    "feedbacks = pd.read_excel(\"Feedback.xlsx\")\n",
    "\n",
    "feedbacks.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e2b420f-4cc2-4dcc-82fe-60b9df900ff5",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "Summarization of dataset prints out total numbers per label type (-1, 0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5e302a1-8f07-42be-b924-1e34206d9089",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'venv (Python 3.12.4)' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'c:/Users/Wayan/Desktop/Sentimental-analysis-of-Professor-Performance/venv/Scripts/python.exe -m pip install ipykernel -U --force-reinstall'"
     ]
    }
   ],
   "source": [
    "# Summarizes the dataset\n",
    "print(\"DATASET\")\n",
    "print(\"DIMENSION: \", feedbacks.shape)\n",
    "print()\n",
    "print(\"SUMMARY\")\n",
    "print(feedbacks.groupby(\"Label\").size()) \n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6641b8f-d9c3-4f6e-a5a9-b4d66a345f00",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "<h2>DATA PREPROCESSING</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a43eb46e",
   "metadata": {},
   "source": [
    "The data must undergo text cleaning and standardization to remove irrelevant information that doesn't contribute to the sentiment detection of text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7540208e-fadc-47ee-b848-2e40b7234667",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'venv (Python 3.12.4)' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'c:/Users/Wayan/Desktop/Sentimental-analysis-of-Professor-Performance/venv/Scripts/python.exe -m pip install ipykernel -U --force-reinstall'"
     ]
    }
   ],
   "source": [
    "# Preprocessing the text\n",
    "def preprocess_text(text):\n",
    "\n",
    "    #Lowercase and Removing special characters\n",
    "    lowercase_text = text.lower()\n",
    "    cleaned_text = re.sub(r\"[^a-zA-Z0-9\\s]\", \"\", lowercase_text) \n",
    "\n",
    "    # Tokenization\n",
    "    tokens = word_tokenize(cleaned_text, \"english\")\n",
    "    \n",
    "\n",
    "    #Removal of stop words\n",
    "\n",
    "    #Declaring English and Tagalog stop words\n",
    "    stop_words = set(stopwords.words('english')) | set([\"akin\",\"aking\",\"ako\",\"alin\",\"am\",\"amin\",\"aming\",\"ang\",\"ano\",\"anumang\",\"apat\",\"at\",\"atin\",\"ating\",\"ay\",\"bababa\",\"bago\",\"bakit\",\"bawat\",\"bilang\",\"dahil\",\"dalawa\",\"dapat\",\"din\",\"dito\",\"doon\",\"gagawin\",\"gayunman\",\"ginagawa\",\"ginawa\",\"ginawang\",\"gumawa\",\"gusto\",\"habang\",\"hanggang\",\"hindi\",\"huwag\",\"iba\",\"ibaba\",\"ibabaw\",\"ibig\",\"ikaw\",\"ilagay\",\"ilalim\",\"ilan\",\"inyong\",\"isa\",\"isang\",\"itaas\",\"ito\",\"iyo\",\"iyon\",\"iyong\",\"ka\",\"kahit\",\"kailangan\",\"kailanman\",\"kami\",\"kanila\",\"kanilang\",\"kanino\",\"kanya\",\"kanyang\",\"kapag\",\"kapwa\",\"karamihan\",\"katiyakan\",\"katulad\",\"kaya\",\"kaysa\",\"ko\",\"kong\",\"kulang\",\"kumuha\",\"kung\",\"laban\",\"lahat\",\"lamang\",\"likod\",\"lima\",\"maaari\",\"maaaring\",\"maging\",\"mahusay\",\"makita\",\"marami\",\"marapat\",\"masyado\",\"may\",\"mayroon\",\"mga\",\"minsan\",\"mismo\",\"mula\",\"muli\",\"na\",\"nabanggit\",\"naging\",\"nagkaroon\",\"nais\",\"nakita\",\"namin\",\"napaka\",\"narito\",\"nasaan\",\"ng\",\"ngayon\",\"ni\",\"nila\",\"nilang\",\"nito\",\"niya\",\"niyang\",\"noon\",\"o\",\"pa\",\"paano\",\"pababa\",\"paggawa\",\"pagitan\",\"pagkakaroon\",\"pagkatapos\",\"palabas\",\"pamamagitan\",\"panahon\",\"pangalawa\",\"para\",\"paraan\",\"pareho\",\"pataas\",\"pero\",\"pumunta\",\"pumupunta\",\"sa\",\"saan\",\"sabi\",\"sabihin\",\"sarili\",\"sila\",\"sino\",\"siya\",\"tatlo\",\"tayo\",\"tulad\",\"tungkol\",\"una\",\"walang\"])\n",
    "\n",
    "    tokens = [token for token in tokens if token not in stop_words]\n",
    "\n",
    "    #Lemmatizing each word\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    tokens = [lemmatizer.lemmatize(token) for token in tokens]\n",
    "    \n",
    "    return ' '.join(tokens)\n",
    "\n",
    "\n",
    "feedbacks[\"processed_feedback\"] = feedbacks[\"Comments\"].apply(preprocess_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6de3cb4c-ec97-45ca-91c5-20f2ee3564e7",
   "metadata": {},
   "source": [
    "Creating a Bag-of-Words representation and vectorizing the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cee28ec5-15c8-445a-b2f5-ee6043aa94ac",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'venv (Python 3.12.4)' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'c:/Users/Wayan/Desktop/Sentimental-analysis-of-Professor-Performance/venv/Scripts/python.exe -m pip install ipykernel -U --force-reinstall'"
     ]
    }
   ],
   "source": [
    "vectorizer = CountVectorizer()\n",
    "features = vectorizer.fit_transform(feedbacks[\"processed_feedback\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7245a5f-9612-40a8-8e42-b3b13f41c664",
   "metadata": {},
   "source": [
    "To get an unbiased estimate of the model’s performance, we need to evaluate it on the data we didn’t use for training. The dataset is splitted using a single-split method."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b00a0f0d-5070-4b04-a506-d06c4f533ab2",
   "metadata": {},
   "source": [
    "80% of the data will be used for training and 20% will be used for testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0adcfa0-4d2d-4fc8-aa37-7d5deeb82386",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'venv (Python 3.12.4)' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'c:/Users/Wayan/Desktop/Sentimental-analysis-of-Professor-Performance/venv/Scripts/python.exe -m pip install ipykernel -U --force-reinstall'"
     ]
    }
   ],
   "source": [
    "x_train, X_test, y_train, y_test = train_test_split(features, feedbacks[\"Label\"], test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84c9365f-f89c-45b1-94bd-0e76fb511461",
   "metadata": {},
   "source": [
    "<h2>MODEL TRAINING AND EVALUATION</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c103f768-19c0-4673-bb4a-7c76374b2197",
   "metadata": {},
   "source": [
    "The model is then trained and tested. To evaluate the model performance metrics such as accuracy, precision, recall, and F1 score will be measured."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d37a131-96d3-4f08-8d4b-2720b1e26054",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'venv (Python 3.12.4)' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'c:/Users/Wayan/Desktop/Sentimental-analysis-of-Professor-Performance/venv/Scripts/python.exe -m pip install ipykernel -U --force-reinstall'"
     ]
    }
   ],
   "source": [
    "model = MultinomialNB()\n",
    "model.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f84ebb2c-4cb5-4dea-93c5-77c9a1c0831f",
   "metadata": {},
   "source": [
    "<h3>Accuracy</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fa9ebea-e878-4752-a321-fa73ede1184e",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'venv (Python 3.12.4)' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'c:/Users/Wayan/Desktop/Sentimental-analysis-of-Professor-Performance/venv/Scripts/python.exe -m pip install ipykernel -U --force-reinstall'"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "308cfed0-1e20-45ed-aa9f-80861c5437b6",
   "metadata": {},
   "source": [
    "<h3>Precision and Recall</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af7a7c5f-8e50-4531-ae4e-999731a2cafe",
   "metadata": {},
   "source": [
    "Precision and recall usees a confusion matrix to introduce them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "193e4d8e-db6f-40fa-892c-f511d00bcb3a",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'venv (Python 3.12.4)' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'c:/Users/Wayan/Desktop/Sentimental-analysis-of-Professor-Performance/venv/Scripts/python.exe -m pip install ipykernel -U --force-reinstall'"
     ]
    }
   ],
   "source": [
    "cm = confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05d11ba8-7b54-4dba-b8cb-021a1b1c86a2",
   "metadata": {},
   "source": [
    "<h4>Visualizing the confusion matrix</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bd65007-eec8-47c9-8d57-9a0d2e24132c",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'venv (Python 3.12.4)' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'c:/Users/Wayan/Desktop/Sentimental-analysis-of-Professor-Performance/venv/Scripts/python.exe -m pip install ipykernel -U --force-reinstall'"
     ]
    }
   ],
   "source": [
    "class_labels = {\n",
    "    -1: \"Negative\",\n",
    "    0: \"Neutral\",\n",
    "    1: \"Positive\"\n",
    "}\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(\n",
    "    cm,\n",
    "    annot=True,\n",
    "    fmt=\"d\",\n",
    "    cmap=\"Blues\",\n",
    "    xticklabels=[class_labels[i] for i in class_labels.keys()],\n",
    "    yticklabels=[class_labels[i] for i in class_labels.keys()],\n",
    ")\n",
    "\n",
    "plt.xlabel(\"Predicted Sentiment\")\n",
    "plt.ylabel(\"Actual Sentiment\")\n",
    "plt.title(\"Confusion Matrix for Sentiment Analysis\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae185087-3f68-469e-85b6-d22d175af1c4",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'venv (Python 3.12.4)' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'c:/Users/Wayan/Desktop/Sentimental-analysis-of-Professor-Performance/venv/Scripts/python.exe -m pip install ipykernel -U --force-reinstall'"
     ]
    }
   ],
   "source": [
    "precision = precision_score(y_test, y_pred, average=\"weighted\")\n",
    "recall = recall_score(y_test, y_pred, average=\"weighted\")\n",
    "\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c001a802-5a79-4162-8632-97a8305b0d17",
   "metadata": {},
   "source": [
    "<h3>F1 score</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a054c0cb-f4d5-4ad1-a60f-756f37b60931",
   "metadata": {},
   "source": [
    "F1 score is the harmonic between precision and recall. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf85a7ac-77e5-4d40-9ea1-d0551d061297",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'venv (Python 3.12.4)' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'c:/Users/Wayan/Desktop/Sentimental-analysis-of-Professor-Performance/venv/Scripts/python.exe -m pip install ipykernel -U --force-reinstall'"
     ]
    }
   ],
   "source": [
    "f1 = f1_score(y_test, y_pred, average=\"weighted\")\n",
    "print(f\"F1 Score: {f1:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35f02ab5-44ee-408d-a7d4-dd3e9cb253e5",
   "metadata": {},
   "source": [
    "<h2>PREDICTING SENTIMENT OF NEW FEEDBACK</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4678fbd-4216-4ad1-9b54-0f1ef51a7b3a",
   "metadata": {},
   "source": [
    "Using gradio to simulate the uploading process and sentimental analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1de15e2b-036b-4192-ae60-816213b480e1",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'venv (Python 3.12.4)' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'c:/Users/Wayan/Desktop/Sentimental-analysis-of-Professor-Performance/venv/Scripts/python.exe -m pip install ipykernel -U --force-reinstall'"
     ]
    }
   ],
   "source": [
    "def sentiment(text):\n",
    "    cleaned_comment = preprocess_text(text)\n",
    "    new_features = vectorizer.transform([cleaned_comment])\n",
    "    predicted_sentiment = model.predict(new_features)[0]\n",
    "\n",
    "    if predicted_sentiment == 1:\n",
    "        sentiment = \"Positive\"\n",
    "    elif predicted_sentiment == 0:\n",
    "        sentiment = \"Neutral\"\n",
    "    elif predicted_sentiment == -1:\n",
    "        sentiment = \"Negative\"\n",
    "\n",
    "    sentiment_output = f\"{text}: {sentiment}\"\n",
    "    return sentiment_output\n",
    "    \n",
    "#Creating a gradio interface\n",
    "app = gr.Interface(\n",
    "    fn=sentiment,\n",
    "    inputs=gr.Textbox(lines=5, placeholder=\"Enter feedback here...\"),\n",
    "    outputs=\"text\",\n",
    "    title=\"Sentimental Analysis of Student Feedback\",\n",
    "    description=\"Analyzing Pamantasan ng Lungsod ng Pasig Student Sentiments Towards Professor Performance: A Naive Bayes Approach\"\n",
    ")\n",
    "app.launch()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
